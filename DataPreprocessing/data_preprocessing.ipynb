{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## NLP Methods for Anime Information Retrieval\n",
    "\n",
    "I tried various NLP methods to get the most out of the natural language query to retrieve anime-specific information.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Data Preprocessing\n",
    "\n",
    "In this sectio'n, we will preprocess the collected data to ensure it is clean and ready for analysis. This includes handling missing values, encoding categorical variables, and normalizing numerical features.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'..\\DataCollection\\anime_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "### One-Hot Encoding Genres\n",
    "\n",
    "Divides the 'genre' column into multiple one-hot encoded sparse columns by extracting all genres from each row.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Each entry in the 'genre' column consists of a list of genres. This function will create a new column for each unique genre found across all rows, and populate these columns with binary values indicating the presence (1) or absence (0) of the genre for each row.\n",
    "\n",
    "Returns:\n",
    "    DataFrame: A new DataFrame with the original data and additional one-hot encoded genre columns.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_genres(df):\n",
    "    # Create a set of all unique genres\n",
    "    unique_genres = set(genre for sublist in df['genres'].apply(eval) for genre in sublist)\n",
    "    \n",
    "    # Create a column for each genre and populate with binary values\n",
    "    for genre in unique_genres:\n",
    "        df[f\"{genre}_genere \"] = df['genres'].apply(lambda x: 1 if genre in eval(x) else 0)\n",
    "    \n",
    "    return df,unique_genres\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "genere_df, Unique_genres = one_hot_encode_genres(df)\n",
    "# df = pd.concat([df, genere_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unique_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Tag Score One-Hot Encoding\n",
    "\n",
    "\n",
    "This function processes the tags column in the anime dataset to create individual columns for each unique tag with their associated rank scores.\n",
    "\n",
    "Key steps:\n",
    "1. Extracts all unique tag names from the tags column, where each entry contains a list of tag dictionaries with  name  and  rank  fields\n",
    "2. For each unique tag, creates a new column named  {tag}_tag_score\n",
    "3. Populates the score columns by looking up the rank value for each tag in the original tags list, defaulting to 0 if tag not present\n",
    "4. Returns the transformed dataframe and set of unique tags\n",
    "\n",
    "The resulting dataframe has a separate column for each tag_s score, allowing for easier analysis of tag distributions and importance across anime titles.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_tags_with_scores(df):\n",
    "    # Create a set of unique tag names\n",
    "    unique_tags = set()\n",
    "    for tags_list in df['tags']:\n",
    "        tags = eval(tags_list)\n",
    "        for tag in tags:\n",
    "            unique_tags.add(tag['name'])\n",
    "    \n",
    "    # Create columns for each tag's score\n",
    "    for tag in unique_tags:\n",
    "        col_name = f\"{tag}_tag_score\"\n",
    "        df[col_name] = df['tags'].apply(lambda x: next((item['rank'] for item in eval(x) if item['name'] == tag), 0))\n",
    "        \n",
    "    return df, unique_tags\n",
    "\n",
    "# Apply the function\n",
    "tags_df, tags = one_hot_encode_tags_with_scores(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(eval(tags)) for tags in df.tags if tags != '[]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    if eval(df.iloc[i].tags) != '[]':\n",
    "        # print(len(eval(df.iloc[i].tags)))\n",
    "        if len(eval(df.iloc[i].tags)) == 68:\n",
    "            print(i)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(df.iloc[12].tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Input text and predefined tags\n",
    "input_text = \"Suggest me an action anime with a pirate and an overpowered male lead and no female_lead.\"\n",
    "tags = [\"pirate\", \"overpowered\", \"action\", \"slavery\", \"female_lead\", \"angels\", \"samurai\", \"dance\"]\n",
    "\n",
    "# TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(vocabulary=tags)\n",
    "tfidf_scores = vectorizer.fit_transform([input_text])\n",
    "\n",
    "# Extract matching tags\n",
    "extracted_tags = [tags[i] for i in tfidf_scores.toarray().argsort()[0] if tfidf_scores[0, i] > 0]\n",
    "\n",
    "print(extracted_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load NLP models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Input text and predefined tags\n",
    "input_text = \"Suggest me an action anime with male lead and no slavery\"\n",
    "tags = [\"pirate\", \"overpowered\", \"action\", \"slavery\", \"male_lead\", \"female_lead\", \"angels\", \"samurai\", \"dance\"]\n",
    "\n",
    "# Detect negations\n",
    "def detect_negations(input_text, tags):\n",
    "    doc = nlp(input_text)\n",
    "    print(doc)\n",
    "    negated_tags = set()\n",
    "    for token in doc:\n",
    "        print(token.dep_)\n",
    "        if token.dep_ == \"neg\":  # Negation dependency\n",
    "            negated_head = token.head.text.lower()\n",
    "            if negated_head in tags:\n",
    "                print(negated_head)\n",
    "                negated_tags.add(negated_head)\n",
    "    return negated_tags\n",
    "\n",
    "# Compute embeddings and similarities\n",
    "input_embedding = model.encode(input_text, convert_to_tensor=True)\n",
    "tag_embeddings = model.encode(tags, convert_to_tensor=True)\n",
    "similarities = cosine_similarity([input_embedding], tag_embeddings)[0]\n",
    "\n",
    "# Adjust scores for negations\n",
    "negated_tags = detect_negations(input_text, tags)\n",
    "tag_scores = []\n",
    "\n",
    "for i, tag in enumerate(tags):\n",
    "    if tag in negated_tags:\n",
    "        tag_scores.append(-similarities[i])  # Negative score for negated tags\n",
    "    else:\n",
    "        tag_scores.append(similarities[i])  # Positive score for relevant tags\n",
    "\n",
    "# Normalize scores\n",
    "tag_scores = np.array(tag_scores)\n",
    "if tag_scores.max() > 0:  # Avoid division by zero\n",
    "    tag_scores = tag_scores / abs(tag_scores).max()\n",
    "\n",
    "# Print results\n",
    "print(\"Tags:\", tags)\n",
    "print(\"Scores:\", tag_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, nlp=nlp):\n",
    "    \"\"\"\n",
    "    Preprocess text for NLP tasks using spaCy\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to be preprocessed\n",
    "        nlp: spaCy language model (defaults to already loaded model)\n",
    "        \n",
    "    Returns:\n",
    "        str: Preprocessed text with lemmatization and stopword removal\n",
    "    \"\"\"\n",
    "    # Process text with spaCy\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    # Remove stopwords and punctuation, lemmatize tokens\n",
    "    tokens = [token.lemma_ for token in doc \n",
    "             if not token.is_stop \n",
    "             and not token.is_punct\n",
    "             and not token.is_space]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    processed_text = ' '.join(tokens)\n",
    "    \n",
    "    return processed_text\n",
    "preprocess_text(\"Suggest me an action anime with pirates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def get_text_embedding(text, model_name='all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Transform natural language text to vector embeddings using SentenceTransformer\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text to be transformed\n",
    "        model_name (str): Name of the HuggingFace model to use\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Vector embedding of the input text\n",
    "    \"\"\"\n",
    "    # Load model (reuse existing if already loaded)\n",
    "    try:\n",
    "        embedding_model = model\n",
    "    except NameError:\n",
    "        embedding_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = embedding_model.encode(preprocess_text(text), convert_to_tensor=True)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "# Example usage\n",
    "text = \"Suggest me an action anime with pirates\"\n",
    "embedding = get_text_embedding(text)\n",
    "print(f\"Embedding shape: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_12=[preprocess_text(df.iloc[12].description),preprocess_text(df.iloc[12].title_english)]\n",
    "for tag in eval(df.iloc[12].tags):\n",
    "    tags_12.append(tag[\"name\"])\n",
    "onepiece=preprocess_text(\" \".join(tags_12))\n",
    "print(onepiece)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime_emb(idx):\n",
    "    tags=[preprocess_text(df.iloc[idx].description) ,preprocess_text(df.iloc[idx].title_english)]\n",
    "    for tag in eval(df.iloc[idx].tags):\n",
    "        tags.append(tag[\"name\"])\n",
    "    txt=preprocess_text(\" \".join(tags))\n",
    "    return get_text_embedding(txt),txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "onepiece_embd=get_text_embedding(onepiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onepiece_embd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity([onepiece_embd], [embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "onepiece_embd,onepiece = anime_emb(12)\n",
    "vinland_embd,vinland = anime_emb(47)\n",
    "input_embedding = get_text_embedding(\"Suggest me an action anime with pirates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vinland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"vinland saga like anime with pirates\"\n",
    "cosine_similarity([anime_emb(47)], [get_text_embedding(input)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df.iloc[178].title_english\n",
    "for i in range(len(df)):\n",
    "    # print(df.iloc[i].id)\n",
    "    if 101348 == df.iloc[i].id:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set()\n",
    "for tags_list in df['tags']:\n",
    "    tags = eval(tags_list)\n",
    "    for tag in tags:\n",
    "        unique_tags.add(tag['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=sorted(list(set(genres)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in tags:\n",
    "    print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define base components\n",
    "\n",
    "\n",
    "# Base templates\n",
    "templates = [\n",
    "    \"Suggest me a [GENRE] anime with a [TAG].\",\n",
    "    \"I want to watch a [GENRE] anime focused on [TAG].\",\n",
    "    \"Looking for a [GENRE] anime with [TAG].\",\n",
    "    \"Recommend me an anime with [TAG].\",\n",
    "    \"Can you suggest a [GENRE] anime?\",\n",
    "    \"Find me a [GENRE] anime with a lot of [TAG].\",\n",
    "    \"What are some [GENRE] anime centered around [TAG]?\",\n",
    "    \"Show me a good [GENRE] anime about [TAG].\",\n",
    "    \"I'm in the mood for a [GENRE] anime with a [TAG].\",\n",
    "    \"Are there any [GENRE] anime featuring [TAG]?\",\n",
    "    \"Tell me about an anime with a lot of [TAG] elements.\",\n",
    "    \"What is a must-watch anime with [TAG]?\",\n",
    "    \"Give me a multi-genre anime combining [GENRE] and [GENRE] with a focus on [TAG].\",\n",
    "    \"Recommend a [GENRE] and [GENRE] anime with [TAG].\",\n",
    "    \"Suggest an anime with [TAG] and some [GENRE] themes.\",\n",
    "    \"What [GENRE] anime has [TAG] as a central theme?\",\n",
    "    \"I need an anime with [TAG], preferably in the [GENRE] genre.\",\n",
    "    \"Can you find an anime with a mix of [GENRE] and [TAG]?\",\n",
    "    \"Recommend a good [GENRE] anime that explores [TAG].\",\n",
    "    \"I want to explore a [GENRE] anime without [TAG].\"\n",
    "]\n",
    "\n",
    "# Data augmentation\n",
    "augmentations = [\n",
    "    \"I'm looking for something similar to [EXAMPLE_ANIME].\",\n",
    "    \"I enjoyed [EXAMPLE_ANIME], any recommendations like that?\",\n",
    "    \"Can you suggest a new anime like [EXAMPLE_ANIME]?\",\n",
    "    \"What's a good follow-up to [EXAMPLE_ANIME]?\",\n",
    "    \"I've heard about [EXAMPLE_ANIME], but I want something different with [TAG].\",\n",
    "    \"[EXAMPLE_ANIME] was amazing; what else is good in [GENRE]?\"\n",
    "]\n",
    "example_anime = [\"Naruto\", \"One Piece\", \"Attack on Titan\", \"Your Lie in April\", \"Steins;Gate\", \"Demon Slayer\"]\n",
    "\n",
    "# Generate 100 unique templates\n",
    "unique_templates = set()\n",
    "\n",
    "while len(unique_templates) < 100:\n",
    "    # Randomly pick a base template and components\n",
    "    template = random.choice(templates)\n",
    "    genre1 = random.choice(genres)\n",
    "    genre2 = random.choice(genres)\n",
    "    tag = random.choice(tags)\n",
    "\n",
    "    # Replace placeholders\n",
    "    sentence = template\n",
    "    if \"[GENRE]\" in template:\n",
    "        sentence = sentence.replace(\"[GENRE]\", genre1, 1)\n",
    "        if \"[GENRE]\" in sentence:  # For multi-genre templates\n",
    "            sentence = sentence.replace(\"[GENRE]\", genre2, 1)\n",
    "    if \"[TAG]\" in template:\n",
    "        sentence = sentence.replace(\"[TAG]\", tag, 1)\n",
    "\n",
    "    # Add augmented examples\n",
    "    if random.random() < 0.3:  # 30% chance to use augmentation\n",
    "        aug_template = random.choice(augmentations)\n",
    "        sentence = aug_template.replace(\"[EXAMPLE_ANIME]\", random.choice(example_anime))\n",
    "        if \"[TAG]\" in aug_template:\n",
    "            sentence = sentence.replace(\"[TAG]\", tag, 1)\n",
    "        if \"[GENRE]\" in aug_template:\n",
    "            sentence = sentence.replace(\"[GENRE]\", genre1, 1)\n",
    "\n",
    "    # Add the sentence to the set\n",
    "    unique_templates.add(sentence)\n",
    "\n",
    "# Print the results\n",
    "for idx, template in enumerate(unique_templates):\n",
    "    print(f\"{idx+1}: {template}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_desc=df.iloc[12].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(description):\n",
    "    return summarizer(description, max_length=200, min_length=20, do_sample=False)[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_summary(one_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "\n",
    "# Suppress errors and fall back to eager mode\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "sentences = [\n",
    "    \"Gold Roger was known as the Pirate King, the strongest and most infamous being to have sailed the Grand Line. The capture and death of Roger by the World Government brought a change throughout the world. His last words before his death revealed the location of the greatest treasure in the world, One Piece. It was this revelation that brought about the Grand Age of Pirates, men who dreamed of finding One Piece (which promises an unlimited amount of riches and fame), and quite possibly the most coveted of titles for the person who found it, the title of the Pirate King.Enter Monkey D. Luffy, a 17-year-old boy that defies your standard definition of a pirate. Rather than the popular persona of a wicked, hardened, toothless pirate who ransacks villages for fun, Luffy’s reason for being a pirate is one of pure wonder; the thought of an exciting adventure and meeting new and intriguing people, along with finding One Piece, are his reasons of becoming a pirate. Following in the footsteps of his childhood hero, Luffy and his crew travel across the Grand Line, experiencing crazy adventures, unveiling dark mysteries and battling strong enemies, all in order to reach One Piece.\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = set()\n",
    "for tags_list in df['tags']:\n",
    "    tags = eval(tags_list)\n",
    "    for tag in tags:\n",
    "        unique_tags.add(tag['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genres = set(genre for sublist in df['genres'].apply(eval) for genre in sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[12].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres_and_tags(id):\n",
    "    genres = eval(df.loc[df['id'] == id, 'genres'].values[0])\n",
    "    tags = {tag['name']: tag[\"rank\"] for tag in eval(df.loc[df['id'] == id, 'tags'].values[0])}\n",
    "    return genres, tags\n",
    "\n",
    "# Example usage\n",
    "genres, tags = get_genres_and_tags(21)\n",
    "print(f\"Genres: {genres}\")\n",
    "print(f\"Tags: {tags}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_1=[]\n",
    "for genre in genres:\n",
    "    gen=f\" One piece anime is a {genre} anime.\"\n",
    "    meta_data_1.append(gen)\n",
    "    for tag in tags:\n",
    "        meta_data_1.append(f\" One piece anime is a  {genre} and {tag} anime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Gold Roger was known as the Pirate King, the strongest and most infamous being to have sailed the Grand Line. The capture and death of Roger by the World Government brought a change throughout the world. His last words before his death revealed the location of the greatest treasure in the world, One Piece. It was this revelation that brought about the Grand Age of Pirates, men who dreamed of finding One Piece (which promises an unlimited amount of riches and fame), and quite possibly the most coveted of titles for the person who found it, the title of the Pirate King.Enter Monkey D. Luffy, a 17-year-old boy that defies your standard definition of a pirate. Rather than the popular persona of a wicked, hardened, toothless pirate who ransacks villages for fun, Luffy’s reason for being a pirate is one of pure wonder; the thought of an exciting adventure and meeting new and intriguing people, along with finding One Piece, are his reasons of becoming a pirate. Following in the footsteps of his childhood hero, Luffy and his crew travel across the Grand Line, experiencing crazy adventures, unveiling dark mysteries and battling strong enemies, all in order to reach One Piece.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"\".join(sentences).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_description\"] = df[\"description\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    anime_genre, anime_tags = get_genres_and_tags(i)\n",
    "    \n",
    "    desc=df.iloc[i].cleaned_description\n",
    "    for gen in anime_genre:\n",
    "        row={}\n",
    "        row[\"description\"]=desc\n",
    "        row[\"genre\"]=gen\n",
    "        row[\"score\"]=1.0\n",
    "        newdata.append(row)\n",
    "    for tag in anime_tags.items():\n",
    "        row={}\n",
    "        row[\"description\"]=desc\n",
    "        row[\"genre\"]=tag[0]\n",
    "        row[\"score\"]=tag[1]/100\n",
    "        newdata.append(row)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedata=pd.DataFrame(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences.append(\" \".join(tags))\n",
    "sentences.append(\" \".join(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_onepiece={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Define base components\n",
    "\n",
    "\n",
    "# Base templates\n",
    "templates = [\n",
    "    \"Suggest me a [GENRE] anime with a [TAG].\",\n",
    "    \"I want to watch a [GENRE] anime focused on [TAG].\",\n",
    "    \"Looking for a [GENRE] anime with [TAG].\",\n",
    "    \"Recommend me an anime with [TAG].\",\n",
    "    \"Can you suggest a [GENRE] anime?\",\n",
    "    \"Find me a [GENRE] anime with a lot of [TAG].\",\n",
    "    \"What are some [GENRE] anime centered around [TAG]?\",\n",
    "    \"Show me a good [GENRE] anime about [TAG].\",\n",
    "    \"I'm in the mood for a [GENRE] anime with a [TAG].\",\n",
    "    \"Are there any [GENRE] anime featuring [TAG]?\",\n",
    "    \"Tell me about an anime with a lot of [TAG] elements.\",\n",
    "    \"What is a must-watch anime with [TAG]?\",\n",
    "    \"Give me a multi-genre anime combining [GENRE] and [GENRE] with a focus on [TAG].\",\n",
    "    \"Recommend a [GENRE] and [GENRE] anime with [TAG].\",\n",
    "    \"Suggest an anime with [TAG] and some [GENRE] themes.\",\n",
    "    \"What [GENRE] anime has [TAG] as a central theme?\",\n",
    "    \"I need an anime with [TAG], preferably in the [GENRE] genre.\",\n",
    "    \"Can you find an anime with a mix of [GENRE] and [TAG]?\",\n",
    "    \"Recommend a good [GENRE] anime that explores [TAG].\",\n",
    "    \"I want to explore a [GENRE] anime without [TAG].\"\n",
    "]\n",
    "# Data augmentation\n",
    "augmentations = [\n",
    "    \"I'm looking for something similar to [EXAMPLE_ANIME].\",\n",
    "    \"I enjoyed [EXAMPLE_ANIME], any recommendations like that?\",\n",
    "    \"Can you suggest a new anime like [EXAMPLE_ANIME]?\",\n",
    "    \"What's a good follow-up to [EXAMPLE_ANIME]?\",\n",
    "    \"I've heard about [EXAMPLE_ANIME], but I want something different with [TAG].\",\n",
    "    \"[EXAMPLE_ANIME] was amazing; what else is good in [GENRE]?\"\n",
    "]\n",
    "example_anime = [\"Naruto\", \"One Piece\", \"Attack on Titan\", \"Your Lie in April\", \"Steins;Gate\", \"Demon Slayer\"]\n",
    "\n",
    "# Generate 100 unique templates\n",
    "unique_templates = set()\n",
    "\n",
    "while len(unique_templates) < 100:\n",
    "    # Randomly pick a base template and components\n",
    "    template = random.choice(templates)\n",
    "    genre1 = random.choice(genres)\n",
    "    genre2 = random.choice(genres)\n",
    "    tag = random.choice(tags)\n",
    "\n",
    "    # Replace placeholders\n",
    "    sentence = template\n",
    "    if \"[GENRE]\" in template:\n",
    "        sentence = sentence.replace(\"[GENRE]\", genre1, 1)\n",
    "        if \"[GENRE]\" in sentence:  # For multi-genre templates\n",
    "            sentence = sentence.replace(\"[GENRE]\", genre2, 1)\n",
    "    if \"[TAG]\" in template:\n",
    "        sentence = sentence.replace(\"[TAG]\", tag, 1)\n",
    "\n",
    "    # Add augmented examples\n",
    "    if random.random() < 0.3:  # 30% chance to use augmentation\n",
    "        aug_template = random.choice(augmentations)\n",
    "        sentence = aug_template.replace(\"[EXAMPLE_ANIME]\", random.choice(example_anime))\n",
    "        if \"[TAG]\" in aug_template:\n",
    "            sentence = sentence.replace(\"[TAG]\", tag, 1)\n",
    "        if \"[GENRE]\" in aug_template:\n",
    "            sentence = sentence.replace(\"[GENRE]\", genre1, 1)\n",
    "\n",
    "    # Add the sentence to the set\n",
    "    unique_templates.add(sentence)\n",
    "\n",
    "# Print the results\n",
    "for idx, template in enumerate(unique_templates):\n",
    "    print(f\"{idx+1}: {template}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data={}\n",
    "\n",
    "for i in range(len(df)):\n",
    "    anchor=random.choice(templates)\n",
    "    if anchor\n",
    "    custom_data[\"anchor\"]= anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_words_in_description(df):\n",
    "    \"\"\"\n",
    "    Returns the maximum number of words present in the 'description' column of the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input dataframe containing a 'description' column.\n",
    "\n",
    "    Returns:\n",
    "        int: The maximum number of words in any description.\n",
    "    \"\"\"\n",
    "    # Fill NaN values with an empty string\n",
    "    df['description'] = df['description'].fillna('')\n",
    "    return df['description'].apply(lambda x: len(clean_text(x).split())).max()\n",
    "\n",
    "# Example usage\n",
    "max_words = max_words_in_description(df)\n",
    "print(f\"Maximum number of words in description: {max_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "yi=df.description.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "thedata.to_csv(\"thedata100.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ge ,tg=get_genres_and_tags(12)\n",
    "tag_=\"\"\n",
    "for k,v in tg.items():\n",
    "    tag_+=k+\", \"\n",
    "tag_+=\", \".join(ge)\n",
    "tag_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_genres_tags_and_description(id):\n",
    "    \"\"\"\n",
    "    Returns the genres and tags of a given id from the dataframe df.\n",
    "\n",
    "    Args:\n",
    "        id (int): The id of the dataframe row.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the name, genres, tags, and description.\n",
    "    \"\"\"\n",
    "    genre, tags = get_genres_and_tags(id)\n",
    "    name_en = df.loc[df['id'] == id, 'title_english'].values[0]\n",
    "    name_jp = df.loc[df['id'] == id, 'title_romaji'].values[0]\n",
    "    desc = df.loc[df['id'] == id, 'cleaned_description'].values[0]\n",
    "    base = f\"Name of the anime is {name_en} and {name_jp}. Genres are {', '.join(genre)} tags are {', '.join(tags.keys())} and description is {desc}\"\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_peice=get_name_genres_tags_and_description(20923)\n",
    "vinland_saga=get_name_genres_tags_and_description(105333)\n",
    "toradora=get_name_genres_tags_and_description(113425)\n",
    "new_1=get_name_genres_tags_and_description(101348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_peice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vinland_saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toradora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"Prashasst/anime-recommendation-model\")\n",
    "\n",
    "\n",
    "\n",
    "# [4, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"anime released in 2022\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode([query,one_peice,vinland_saga,toradora,new_1])\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_id=[]\n",
    "embeddings_lst=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_id2=[]\n",
    "embeddings_lst2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9993,len(df)):\n",
    "    if i%500==0:\n",
    "        print(i)\n",
    "    anime_id=df.iloc[i].id\n",
    "    text=get_name_genres_tags_and_description(anime_id)\n",
    "    emb=model.encode(text)\n",
    "    embeddings_lst2.append(emb)\n",
    "    embeddings_id2.append(anime_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_id.extend(embeddings_id2)\n",
    "embeddings_lst.extend(embeddings_lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"embeddings_id.npy\",embeddings_id)\n",
    "np.save(\"embeddings.npy\",embeddings_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_lst[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prashasst_favourits=[\n",
    "    \"Prashasst's favourite anime is One Piece\",\n",
    "    \"Prashasst likes Vinland Saga\",\n",
    "    \"Love, Chunibyo & Other Delusions is also one of Prashasst's favourite anime\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "anime_embeddings = np.array(embeddings_lst)\n",
    "\n",
    "\n",
    "# Build FAISS index\n",
    "index = faiss.IndexFlatL2(768)  # L2 distance\n",
    "index.add(anime_embeddings)  # Add embeddings in the same order as the anime_id_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"anime_faiss.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Suggest a pirate anime like onepiece\"\n",
    "query_embedding = model.encode(query).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "# query_embedding = model.encode(query).reshape(1, -1)  # Reshape to 2D array\n",
    "distances, indices = index.search(query_embedding, k=5)  # Search for top 5 matches\n",
    "\n",
    "# indices is a 2D array: [[index1, index2, index3, ...]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices[0]:    \n",
    "    id= embeddings_id[i]\n",
    "    anime_name=df.loc[df['id'] == id, 'title_english'].values[0]\n",
    "    print(anime_name)\n",
    "    # print(get_name_genres_tags_and_description(embeddings_id[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_anime(query, k=5):\n",
    "    \"\"\"\n",
    "    Recommends anime based on a query using a FAISS index and a SentenceTransformer model.\n",
    "\n",
    "    Args:\n",
    "        query (str): The input query to find similar anime.\n",
    "        index: The FAISS index to search for similar anime.\n",
    "        model: The SentenceTransformer model used to encode the query.\n",
    "        anime_embeddings: The embeddings of anime descriptions.\n",
    "        embeddings_id: The ids of the anime embeddings.\n",
    "        df (pd.DataFrame): The dataframe containing anime information.\n",
    "        k (int): The number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of recommended anime titles.\n",
    "    \"\"\"\n",
    "\n",
    "    #  index=index\n",
    "    # model=model, anime_embeddings=anime_embeddings, embeddings_id=embeddings_id, df=df,\n",
    "\n",
    "\n",
    "    # Encode the query\n",
    "    query_embedding = model.encode(query).reshape(1, -1)  # Reshape to 2D array\n",
    "\n",
    "    # Search for similar anime\n",
    "    distances, indices = index.search(query_embedding, k=k)\n",
    "\n",
    "    # Get the anime titles\n",
    "    recommended_anime = []\n",
    "    for i in indices[0]:\n",
    "        anime_id = embeddings_id[i]\n",
    "        # anime_name = df.loc[df['id'] == anime_id, 'title_english'].values[0]\n",
    "        # if pd.isna(anime_name):\n",
    "        #     anime_name = df.loc[df['id'] == anime_id, 'title_romaji'].values[0]\n",
    "        recommended_anime.append(anime_id)\n",
    "\n",
    "    return {\"ids\":recommended_anime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"indian moviee\"\n",
    "recommend_anime(query,k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "# Create the Gradio app\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Anime Recommendation System\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query = gr.Textbox(label=\"Enter your anime preferences or query:\")\n",
    "        top_k = gr.Slider(1, 10, value=5, label=\"Number of Recommendations\")\n",
    "\n",
    "    with gr.Row():\n",
    "        recommend_button = gr.Button(\"Get Recommendations\")\n",
    "        output = gr.JSON(label=\"Recommended Anime\")\n",
    "\n",
    "    recommend_button.click(recommend_anime, inputs=[query, top_k], outputs=output)\n",
    "\n",
    "# Launch the app\n",
    "app.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Gradio app\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## Anime Recommendation System\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        query = gr.Textbox(label=\"Enter your anime preferences or query:\")\n",
    "        top_k = gr.Slider(1, 10, value=5, label=\"Number of Recommendations\")\n",
    "\n",
    "    with gr.Row():\n",
    "        recommend_button = gr.Button(\"Get Recommendations\")\n",
    "        output = gr.Textbox(label=\"Recommended Anime\", lines=10)\n",
    "\n",
    "    recommend_button.click(recommend_anime, inputs=[query, top_k], outputs=output)\n",
    "\n",
    "# Launch the app\n",
    "# app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=np.load(\"embeddings_id.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
