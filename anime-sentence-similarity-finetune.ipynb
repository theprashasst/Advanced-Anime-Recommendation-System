{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas sentence_transformers scikit-learn datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()  # This will prompt you to enter your Hugging Face API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "thedata=pd.read_csv(r\"/kaggle/input/anime-sentence-similarity-csv/thedata2.csv\")\n",
    "# thedata=pd.read_csv(r\"/kaggle/input/anime-recom-100/thedata100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sentences = [\n",
    "#     \"suggest me a action and adventure anime with pirate\",\n",
    "#     \"suggest me a romance anime\",\n",
    "#     \"suggest me a anime with adventure\",\n",
    "#     \"toradora is a comedy anime with highschool romance\"\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# sentences = [\n",
    "#     \"suggest me a action and adventure anime\",\n",
    "#     \"Attack in titan is a anime where humans fight against titans\",\n",
    "#     \"One piece is a anime about a pirate named Monkey D. Luffy\",\n",
    "#     \"toradora is a romance anime\"\n",
    "# ]\n",
    "# embeddings = model.encode(sentences)\n",
    "\n",
    "# similarities = model.similarity(embeddings, embeddings)\n",
    "# print(similarities)\n",
    "# [3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# thedata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from sentence_transformers import InputExample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers.readers import InputExample\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction\n",
    "from transformers import TrainingArguments\n",
    "from sentence_transformers import (\n",
    "    SentenceTransformer,\n",
    "    SentenceTransformerTrainer,\n",
    "    SentenceTransformerTrainingArguments,\n",
    "    SentenceTransformerModelCardData,\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "train_data, temp_data = train_test_split(thedata, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Prepare the datasets for training\n",
    "# train_examples = [\n",
    "#     InputExample(texts=[row['description'], row['genre']], label=float(row['score'])) \n",
    "#     for _, row in train_data.iterrows()\n",
    "# ]\n",
    "# val_examples = [\n",
    "#     InputExample(texts=[row['description'], row['genre']], label=float(row['score'])) \n",
    "#     for _, row in val_data.iterrows()\n",
    "# ]\n",
    "# test_examples = [\n",
    "#     InputExample(texts=[row['description'], row['genre']], label=float(row['score'])) \n",
    "#     for _, row in test_data.iterrows()\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"description\": list(train_data[\"description\"]),\n",
    "    \"genre\" :list(train_data[\"genre\"]),\n",
    "    \"label\" :list(train_data[\"score\"])\n",
    "})\n",
    "\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"description\": list(val_data[\"description\"]),\n",
    "    \"genre\": list(val_data[\"genre\"]),\n",
    "    \"label\": list(val_data[\"score\"])\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"description\": list(test_data[\"description\"]),\n",
    "    \"genre\": list(test_data[\"genre\"]),\n",
    "    \"label\": list(test_data[\"score\"])\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Load a pretrained SentenceTransformer model\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Define a loss function\n",
    "loss = CosineSimilarityLoss(model=model)\n",
    "\n",
    "# Create evaluators for validation and test datasets\n",
    "val_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=val_dataset[\"description\"],\n",
    "    sentences2=val_dataset[\"genre\"],\n",
    "    scores=val_dataset[\"label\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"anime-recommendation-dev\"\n",
    ")\n",
    "\n",
    "test_evaluator = EmbeddingSimilarityEvaluator(\n",
    "    sentences1=test_dataset[\"description\"],\n",
    "    sentences2=test_dataset[\"genre\"],\n",
    "    scores=test_dataset[\"label\"],\n",
    "    main_similarity=SimilarityFunction.COSINE,\n",
    "    name=\"anime-recommendation-test\"\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"models/anime-recommendation\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    logging_steps=1,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    save_total_limit=2,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Define a Trainer\n",
    "\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=val_evaluator\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_evaluator(model)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"models/anime_recom/final\")\n",
    "\n",
    "# (Optional) Push the model to the Hugging Face Hub\n",
    "model.push_to_hub(\"anime-recommendation-model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"one piece\",\n",
    "    \"Attack in titan \",\n",
    "    \"suggest me a romance anime\",\n",
    "    \"toradora\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "# model.predict(\"suggest me a action and adventure anime with pirate\")\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6372255,
     "sourceId": 10295648,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6372901,
     "sourceId": 10296469,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
